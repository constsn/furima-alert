name: ğŸ›’ Furima Scraping Automation

on:
  schedule:
    - cron: '*/30 15-16 * * *' # JST 0:00ã€œ1:00
    - cron: '*/30 23-23 * * *' # JST 8:00
    - cron: '*/30 0-14 * * *' # JST 9:00ã€œ23:00

  workflow_dispatch:
    inputs:
      reason:
        description: 'æ‰‹å‹•å®Ÿè¡Œã®ç†ç”±'
        required: false
        default: 'Manual execution'

jobs:
  scrape:
    name: ğŸ” Execute Scraping
    runs-on: ubuntu-latest
    timeout-minutes: 90

    steps:
      - name: ğŸ“‹ Job Information
        run: |
          echo "ğŸš€ Starting Mercari scraping job"
          echo "â° Execution time: $(date)"
          echo "ğŸ¯ Reason: ${{ github.event.inputs.reason || 'Scheduled execution' }}"
          echo "ğŸ”§ GitHub Actor: ${{ github.actor }}"

      - name: ğŸ¥ Health Check Railway App
        run: |
          echo "ğŸ¥ Checking Railway app health..."
          response=$(curl -w "%{http_code}" -s -o health.txt \
            --max-time 30 \
            https://furima-alert-production.up.railway.app/api/scrape?health=true)

          echo "Health check status: $response"
          cat health.txt

          if [ $response -ne 200 ]; then
            echo "âš ï¸ Health check failed, but continuing..."
          else
            echo "âœ… Railway app is healthy"
          fi

      - name: ğŸ›’ Execute Mercari Scraping
        run: |
          echo "ğŸ” Starting scraping process..."

          response=$(curl -w "%{http_code}" -s -o scrape_result.txt \
            -X POST \
            -H "Authorization: Bearer ${{ secrets.CRON_SECRET }}" \
            -H "Content-Type: application/json" \
            -H "User-Agent: GitHub-Actions-Scraper/1.0" \
            --max-time 5400 \
            https://furima-alert-production.up.railway.app/api/scrape)

          echo "ğŸ“Š HTTP Status Code: $response"
          echo "ğŸ“„ Response Body:"
          cat scrape_result.txt

          if [ $response -eq 200 ]; then
            echo "âœ… Scraping completed successfully!"
            
            if command -v jq &> /dev/null; then
              duration=$(cat scrape_result.txt | jq -r '.duration // "unknown"')
              timestamp=$(cat scrape_result.txt | jq -r '.timestamp // "unknown"')
              echo "â±ï¸ Duration: $duration"
              echo "ğŸ•’ Completed at: $timestamp"
            fi
            
          elif [ $response -eq 401 ]; then
            echo "ğŸ” Authentication failed - check CRON_SECRET"
            exit 1
            
          elif [ $response -eq 500 ]; then
            echo "ğŸ’¥ Internal server error during scraping"
            exit 1
            
          else
            echo "âŒ Unexpected response code: $response"
            exit 1
          fi

      - name: ğŸ“ˆ Job Summary
        if: always()
        run: |
          echo "ğŸ“Š === Job Summary ==="
          echo "ğŸ¯ Workflow: ${{ github.workflow }}"
          echo "ğŸ”„ Run Number: ${{ github.run_number }}"
          echo "â° Started: $(date -d '90 minutes ago')"
          echo "ğŸ Finished: $(date)"

          if [ -f scrape_result.txt ]; then
            echo "ğŸ“„ Final Result:"
            cat scrape_result.txt
          fi
